{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is Word Embedding? \n",
    "- Word embedding is a language model technique that maps words to vectors of real numbers\n",
    "- It represents words in vector space in several different \n",
    "- Word2Vec consists of models for generating word embedding, these are shallow 2 layer neutral networks\n",
    "- Word2Vec has one input layer, one hidden layer, and onw output layer\n",
    "\n",
    "What is Word2Vec?\n",
    "- Word2Vec makes the assumption that the meaning of a word can be inferred by the company it keeps.\n",
    "- Word2Vec allows words to be represented as vectors in a continuous vector space\n",
    "- Word2Vec is an effort to map high dimensional vectors to capture semantic relationships between words\n",
    "- Words that have similar meanings should have similar vectors\n",
    "\n",
    "What are Word2Vecs two architectures?\n",
    "- CBOW (Continuous Bag of Words) &rarr; This model predicts the target word based on the context words. This is better for larger datasets\n",
    "<img src=\"media/CBOW.png\" alt=\"CBOW\" style=\"width: 400px; height: 400px;\">\n",
    "\n",
    "\n",
    "- Skip-gram &rarr; This model predicts the context words based on the target word. This is better for smaller datasets with rarer words.\n",
    "<img src=\"media/Skip-gram.png\" alt=\"CBOW\" style=\"width: 400px; height: 400px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog True 7.0336733 False\n",
      "cat True 6.6808186 False\n",
      "banana True 6.700014 False\n",
      "afskfsd False 0.0 True\n"
     ]
    }
   ],
   "source": [
    "import spacy # importing spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\") \n",
    "tokens = nlp(\"dog cat banana afskfsd\")\n",
    "\n",
    "for token in tokens:\n",
    "   print(token.text, token.has_vector, token.vector_norm, token.is_oov)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`nlp = spacy.load(\"en_core_web_lg\")` is downloading the largest english model which is a pipeline trained on written text such as vocabluary, syntax, and entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tokens = nlp(\"dog cat banana afskfsd\")` this looks for the certain words within nlp and assigns them to tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`for token in tokens:`\\\n",
    "   `print(token.text, token.has_vector, token.vector_norm, token.is_oov)`\\\n",
    "This creates a for loop where it iterates through token and prints the name, if it's a vector, its vector, and if it's not a vector for each "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cat, banana, and dog are all common vocabulary words so they are all apart of the pipelines vocab and come with a vector.\n",
    "- afskfsd is uncommon and out-of-vocabulary which means its vector consists of 300 dimensions of `0` which in summary means its practically non existant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like salty fries and hamburgers. <-> Fast food tastes very good. 0.7687609195709229\n",
      "salty fries <-> hamburgers 0.6949787735939026\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")  # make sure to use larger package!\n",
    "doc1 = nlp(\"I like salty fries and hamburgers.\")\n",
    "doc2 = nlp(\"Fast food tastes very good.\")\n",
    "\n",
    "# Similarity of two documents\n",
    "print(doc1, \"<->\", doc2, doc1.similarity(doc2))\n",
    "# Similarity of tokens and spans\n",
    "french_fries = doc1[2:4]\n",
    "burgers = doc1[5]\n",
    "print(french_fries, \"<->\", burgers, french_fries.similarity(burgers))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "doc holds an array of tokens"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
